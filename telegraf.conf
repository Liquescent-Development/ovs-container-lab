# Telegraf Configuration for OVS Container Lab
# Collects metrics from OVS and OVN exporters and sends to InfluxDB

# Global tags can be specified here in key="value" format.
[global_tags]
  environment = "ovs-lab"

# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "10s"
  ## Rounds collection interval to 'interval'
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  collection_jitter = "0s"

  ## Default flushing interval for all outputs.
  flush_interval = "10s"
  ## Jitter the flush interval by a random amount.
  flush_jitter = "0s"

  ## Logging configuration:
  debug = false
  quiet = false
  logfile = ""

  ## Override default hostname, if empty use os.Hostname()
  hostname = "telegraf"
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false

###############################################################################
#                            PROCESSOR PLUGINS                                #
###############################################################################

# Smart enrichment - add hostname for multi-host visibility
# For tenant_id enrichment, we rely on the external_ids metrics
[[processors.starlark]]
  ## The Starlark script to run
  source = '''
# This script adds ovs_host tag to all metrics with system_id
# In a multi-host deployment, system_id identifies the physical host

def apply(metric):
    # Extract tenant_id from external_ids metrics and propagate as a tag
    if "ovs_ovs_interface_external_ids" in metric.name:
        key = metric.tags.get("key")
        value = metric.tags.get("value")

        # For tenant_id external_id, add it as a tag
        if key == "tenant_id" and value:
            metric.tags["tenant_id"] = value

        # For network_id external_id, add it as a tag
        if key == "network_id" and value:
            metric.tags["network_id"] = value

        # For container_id external_id, add it as a tag (but keep low cardinality in mind)
        if key == "container_id" and value:
            # We'll add this to tags but it increases cardinality
            metric.tags["container_id"] = value

    # Add ovs_host tag from system_id for all OVS metrics
    system_id = metric.tags.get("system_id")
    if system_id:
        metric.tags["ovs_host"] = system_id

    return metric
'''

###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################

# Configuration for sending metrics to InfluxDB
[[outputs.influxdb]]
  ## The full HTTP or UDP URL for your InfluxDB instance.
  urls = ["http://influxdb:8086"]

  ## The target database for metrics; will be created as needed.
  database = "ovs_metrics"

  ## If true, no CREATE DATABASE queries will be sent.
  skip_database_creation = false

  ## Name of existing retention policy to write to.  Empty string writes to
  ## the default retention policy.
  retention_policy = ""

  ## Write consistency (clusters only), can be: "any", "one", "quorum", "all".
  write_consistency = "any"

  ## Timeout for HTTP messages.
  timeout = "5s"

  ## HTTP Basic Auth
  username = "admin"
  password = "admin"

###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################

# Read metrics from OVS Exporter (Prometheus format)
[[inputs.prometheus]]
  ## OVS Exporter endpoint (running on host VM)
  ## Use the docker0 bridge IP to reach the host from containers
  urls = ["http://172.17.0.1:9475/metrics"]

  ## Metric version controls the mapping from Prometheus metrics into Telegraf metrics.
  ## Version 1 creates separate measurements for each metric (easier to query)
  metric_version = 1

  ## Specify timeout duration for slower hosts
  timeout = "5s"

  ## Optional TLS Config
  # tls_ca = "/etc/telegraf/ca.pem"
  # tls_cert = "/etc/telegraf/cert.pem"
  # tls_key = "/etc/telegraf/key.pem"
  ## Use TLS but skip chain & host verification
  # insecure_skip_verify = false

  ## Add prefix to all metric names
  name_prefix = "ovs_"

  ## Use metric_version 1 for separate measurements
  ## Collect all metrics from OVS exporter
  # fieldpass removed - with metric_version 1, filtering happens at measurement level

  ## Add tags to identify the source
  [inputs.prometheus.tags]
    source = "ovs_exporter"
    exporter = "ovs"

# Read metrics from OVN Exporter (if available)
# DISABLED: ovn-central container is not running by default
# Uncomment this section if you start ovn-central container
# [[inputs.prometheus]]
#   ## OVN Exporter endpoint (running in ovn-central container)
#   urls = ["http://ovn-central:9476/metrics"]
#   metric_version = 1
#   timeout = "5s"
#   interval = "30s"
#   name_prefix = "ovn_"
#   [inputs.prometheus.tags]
#     source = "ovn_exporter"
#     exporter = "ovn"

# Collect Docker container metrics
# DISABLED: Docker socket permissions issue in container
# To enable, fix permissions or run Telegraf on host
# [[inputs.docker]]
#   endpoint = "unix:///var/run/docker.sock"
#   gather_services = false
#   container_name_include = []
#   container_name_exclude = []
#   container_state_include = ["created", "restarting", "running", "removing", "paused", "exited", "dead"]
#   container_state_exclude = []
#   timeout = "5s"
#   perdevice_include = ["cpu", "blkio", "network"]
#   total_include = ["cpu", "blkio", "network"]
#   docker_label_include = ["ovs-lab", "vpc", "tier", "component"]
#   docker_label_exclude = []

# Collect system metrics from the Telegraf container itself
[[inputs.cpu]]
  ## Whether to report per-cpu stats or not
  percpu = true
  ## Whether to report total system cpu stats or not
  totalcpu = true
  ## If true, collect raw CPU time metrics.
  collect_cpu_time = false
  ## If true, compute and report the sum of all non-idle CPU states.
  report_active = false

[[inputs.disk]]
  ## By default stats will be gathered for all mount points.
  ## Set mount_points will restrict the stats to only the specified mount points.
  # mount_points = ["/"]

  ## Ignore mount points by filesystem type.
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]

[[inputs.diskio]]
  ## By default, telegraf will gather stats for all devices including
  ## disk partitions.
  ## Setting devices will restrict the stats to the specified devices.
  # devices = ["sda", "sdb", "vd*"]

[[inputs.mem]]
  # No configuration needed

[[inputs.net]]
  ## By default, telegraf gathers stats from any up interface (excluding loopback)
  ## Setting interfaces will tell it to gather these explicit interfaces,
  ## regardless of status.
  # interfaces = ["eth0"]
  ##
  ## On linux systems telegraf also collects protocol stats.
  ## Setting ignore_protocol_stats to true will skip reporting of protocol metrics.
  # ignore_protocol_stats = false

[[inputs.processes]]
  # No configuration needed

[[inputs.system]]
  # No configuration needed

# Optional: HTTP listener for custom metrics
[[inputs.http_listener_v2]]
  ## Address and port to host HTTP listener on
  service_address = ":8080"

  ## Paths to listen to (replaces deprecated 'path')
  paths = ["/telegraf"]

  ## HTTP methods to accept
  methods = ["POST", "PUT"]

  ## maximum duration before timing out read of the request
  read_timeout = "10s"
  ## maximum duration before timing out write of the response
  write_timeout = "10s"

  ## Maximum allowed HTTP request body size in bytes
  max_body_size = "1MB"

  ## Data format to expect
  data_format = "influx"